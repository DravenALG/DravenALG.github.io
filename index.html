<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Xiao-Ming Wu</title>

    <meta name="author" content="Xiao-Ming Wu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/leaf.png" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">

              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/myself.jpg" target="_blank"><img style="width:85%;max-width:100%;object-fit: cover;border-radius: 75px" alt="profile photo" src="images/myself.jpg" class="hoverZoomLink"></a>
              </td>

              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: left;">
                  Xiao-Ming Wu
                </p>
                <p>
                  M.S. student
                </p>
                <p>
                  School of Computer Science and Engineering
                </p>
                <p>
                  Sun Yat-sen University
                </p>
                <p>
                  wuxm65@mail2.sysu.edu.cn
                </p>
                <p style="text-align:left">
                  <a href="https://scholar.google.com/citations?hl=zh-CN&user=Li7oZpsAAAAJ" target="_blank">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/DravenALG" target="_blank">Github</a>
                </p>
              </td>

            </tr>
          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 20px;"><tbody>
            <tr>
              <td style="width:100%; vertical-align:middle">
                <h2>
                  Biography
                </h2>
                <p>
                  I'm currently a second-year master student at <a href="https://www.sysu.edu.cn" target="_blank">Sun Yat-sen University</a>, advised by Prof. <a href="https://www.isee-ai.cn/~zhwshi/" target="_blank">Wei-Shi Zheng</a>, where I cultivate a good taste in scientific research.
                  Previously, I obtain my B.E. degree in <a href="https://www.sdu.edu.cn/index.htm" target="_blank">Shandong University</a>. At that time, I had my first attempt on scientific research, advised by <a href="https://faculty.sdu.edu.cn/luoxin/zh_CN/index.htm" target="_blank">Xin Luo</a> and <a href="http://mima.sdu.edu.cn/Members/xinshunxu/index.htm" target="_blank">Xin-Shun Xu</a>.
                </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 20px;"><tbody>
            <tr>
              <td style="width:100%; vertical-align:middle">
                <h2>Research Interests</h2>
                <p>
                  <em class="ref">
                    Research is for curiosity and fun.
                  </em>
                </p>
                <p>
                  Standing at the turning point of AGI, I am curious about how to build a representation system as strong as humans. Thus, I am interested in <strong>deep representation learning</strong>, mainly on the areas of <strong>representation learning framework</strong>, <strong>self-supervised learning</strong> and <strong>network architecture design</strong>.
                </p>
                <p>
                  During the past years, I have been working on the topics of lightweight representation learning, robotics grasping, diffusion model applications, and hashing retrieval.
                  Participating in diverse research areas broadens my horizon about deep learning and computer vision.
                </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 20px;"><tbody>
            <tr>
              <td style="width:25%; vertical-align:middle">
                <h2>Publications</h2>
                <p>
                  Below are my publications (show by date). My first author works are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding-bottom: 15px; width:25%; vertical-align:middle">
                <a href="https://arxiv.org/abs/2403.11157" target="_blank">
                  <span class="papertitle">Selective Hourglass Mapping for Universal Image Restoration Based on Diffusion Model</span>
                </a>
                <br>
                Dian Zheng, <strong>Xiao-Ming Wu</strong>, Zuhao Liu, Jingke Meng, Wei-Shi Zheng*
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2024.
                <br>
                <a href="https://arxiv.org/abs/2403.11157" target="_blank">paper</a>
                /
                <a href="https://github.com/iSEE-Laboratory/DiffUIR" target="_blank">code</a>
              </td>
            </tr>

            <tr>
              <td style="padding-bottom: 15px; width:25%; vertical-align:middle">
                <a href="https://arxiv.org/abs/2308.15989" target="_blank">
                  <span class="papertitle">DiffuVolume: Diffusion Model for Volume based Stereo Matching</span>
                </a>
                <br>
                Dian Zheng, <strong>Xiao-Ming Wu</strong>, Zuhao Liu, Jingke Meng, Wei-Shi Zheng*
                <br>
                <em>arXiv preprint arXiv:2308.15989</em>, submitted to <em>International Journal of Computer Vision (IJCV)</em>.
                <br>
                <a href="https://arxiv.org/abs/2308.15989" target="_blank">paper</a>
                /
                <a href="https://github.com/iSEE-Laboratory/DiffuVolume" target="_blank">code</a>
              </td>
            </tr>

            <tr>
              <td style="padding-bottom: 15px; width:25%; vertical-align:middle" bgcolor="#ffffd0">
                <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Estimator_Meets_Equilibrium_Perspective_A_Rectified_Straight_Through_Estimator_for_ICCV_2023_paper.html" target="_blank">
                  <span class="papertitle">Estimator Meets Equilibrium Perspective: A Rectified Straight Through Estimator for Binary Neural Networks Training</span>
                </a>
                <br>
                <strong>Xiao-Ming Wu</strong>, Dian Zheng, Zuhao Liu, Wei-Shi Zheng*
                <br>
                <em>International Conference on Computer Vision (ICCV)</em>, 2023
                <br>
                <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Estimator_Meets_Equilibrium_Perspective_A_Rectified_Straight_Through_Estimator_for_ICCV_2023_paper.html" target="_blank">paper</a>
                /
                <a href="https://github.com/DravenALG/ReSTE" target="_blank">code</a>
                <p style="margin-bottom: 0px">
                  We design a new gradient estimator to balance the estimating error and the gradient stability well, which is rational and capable of flexibly balancing the estimating error with the gradient stability, enabling robust binary neural networks training.
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding-bottom: 15px; width:25%; vertical-align:middle">
                <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Liu_Generating_Anomalies_for_Video_Anomaly_Detection_With_Prompt-Based_Feature_Mapping_CVPR_2023_paper.html" target="_blank">
                  <span class="papertitle">Generating Anomalies for Video Anomaly Detection with Prompt-based Feature Mapping</span>
                </a>
                <br>
                Zuhao Liu, <strong>Xiao-Ming Wu</strong>, Dian Zheng, Kun-Yu Lin, Wei-Shi Zheng*
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2023
                <br>
                <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Liu_Generating_Anomalies_for_Video_Anomaly_Detection_With_Prompt-Based_Feature_Mapping_CVPR_2023_paper.html" target="_blank">paper</a>
              </td>
            </tr>

            <tr>
              <td style="padding-bottom: 15px; width:25%; vertical-align:middle">
                <a href="https://dl.acm.org/doi/abs/10.1145/3511808.3557488" target="_blank">
                  <span class="papertitle">Weakly-Supervised Online Hashing with Refined Pseudo Tags</span>
                </a>
                <br>
                Chen-Lu Ding, Xin Luo*, <strong>Xiao-Ming Wu</strong>, Yu-Wei Zhan, Rui Li, Hui Zhang, and Xin-Shun Xu
                <br>
                <em>Conference on Information and Knowledge Management (CIKM)</em>, 2022
                <br>
                <a href="https://dl.acm.org/doi/abs/10.1145/3511808.3557488" target="_blank">paper</a>
                /
                <a href="https://github.com/oceanoceanna/WOH-RPT" target="_blank">code</a>
              </td>
            </tr>

            <tr>
              <td style="padding-bottom: 15px; width:25%; vertical-align:middle" bgcolor="#ffffd0">
                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20346" target="_blank">
                  <span class="papertitle">Online Enhanced Semantic Hashing Towards Effective and Efficient Retrieval for Streaming Multi-Modal Data</span>
                </a>
                <br>
                <strong>Xiao-Ming Wu</strong>, Xin Luo*, Yu-Wei Zhan, Chen-Lu Ding, Zhen-Duo Chen, Xin-Shun Xu
                <br>
                <em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2022
                <br>
                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20346" target="_blank">paper</a>
                /
                <a href="https://github.com/DravenALG/OASIS" target="_blank">code</a>
                <p style="margin-bottom: 0px">
                  We design novel semantic-enhanced representation for data, which could help handle the new coming classes and mitigate the consistent problem in incremental online hashing.
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding-bottom: 15px; width:25%; vertical-align:middle">
                <a href="https://www.sciencedirect.com/science/article/pii/S0031320321004428" target="_blank">
                  <span class="papertitle">Discrete Online Cross-Modal Hashing</span>
                </a>
                <br>
                Yu-Wei Zhan, Yong-Xin Wang, Yu Sun, <strong>Xiao-Ming Wu</strong>, Xin Luo*, and Xin-Shun Xu
                <br>
                <em>Pattern Recognition (PR)</em>, 2022
                <br>
                <a href="https://www.sciencedirect.com/science/article/pii/S0031320321004428" target="_blank">paper</a>
                /
                <a href="https://github.com/yw-zhan/DOCH" target="_blank">code</a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 20px;"><tbody>
          <tr>
            <td style="width:100%; vertical-align:middle">
              <h2>
                Academic Service
              </h2>
              <p>
                Journal Reviewer: Pattern Analysis and Machine Intelligence (TPAMI), Pattern Recognition (PR)
              </p>
              <p>
                Conference Reviewer: Computer Vision and Pattern Recognition (CVPR) 2024
              </p>
            </td>
          </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 20px;"><tbody>
          <tr>
            <td style="width:100%; vertical-align:middle">
              <h2>
                Awards
              </h2>
              <p>
                <div style="padding-bottom: 5px"> National Scholarship of China for Guaduate Student (研究生国家奖学金), 2023 </div>
                <div style="padding-bottom: 5px"> First Prize, Academic Scholarship of Sun Yat-Sen University (中山大学学业一等奖学金), 2022, 2023 </div>
                <div style="padding-bottom: 5px"> Honorable Bachelor Degree of Shandong University (山东大学荣誉学士学位), 2022 </div>
                <div style="padding-bottom: 5px"> National Scholarship of China for Underguaduate Student  (本科生国家奖学金), 2019, 2021 </div>
                <div style="padding-bottom: 5px"> First Prize, Academic Scholarship of Shandong University (山东大学学业一等奖学金), 2019, 2020, 2021 </div>
              </p>
            </td>
          </tr>
          </tbody></table>

        </td>
      </tr>
    </table>
  </body>
</html>
