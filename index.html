<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Xiao-Ming Wu</title>

    <meta name="author" content="Xiao-Ming Wu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/Naruto.png" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel='stylesheet' href='https://chinese-fonts-cdn.deno.dev/packages/xuandongkaishu/dist/XuandongKaishu/result.css' />
    
  </head>

  <body>

    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom: 30px"><tbody>
      <tr style="padding:0px">
        <td class="fixed-header" style="font-size: larger">
          <a href="https://dravenalg.github.io" style="padding-right: 150px; font-size: large;" class="header_name"><img src="images/Naruto.png" style="width: 20px"> Xiao-Ming Wu</a>
          <a href="#bio" style="padding-right: 30px;padding-left: 30px" class="header_navi">Bio</a>
          <a href="#publication" style="padding-right: 30px;padding-left: 30px" class="header_navi">Publications</a>
          <a href="#service" style="padding-right: 30px;padding-left: 30px" class="header_navi">Services</a>
          <a href="#award" style="padding-right: 30px;padding-left: 30px" class="header_navi">Awards</a>
        </td>
      </tr>
    </tbody></table>

    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 20px;"><tbody>
            <tr>
              <td class="personal_image" style="padding:2.5%; width:40%;max-width:40%">
                <img style="width:70%;max-width:100%;object-fit: cover;border-radius: 200px" alt="profile photo" src="images/myself.jpg" class="personal_img">
              </td>

              <td style="width:63%;vertical-align:middle">
                <p class="name" style="text-align: left;">
                  Xiao-Ming Wu <span style="padding-left: 5px" class="chinese_name">‰ºçÊôìÈ∏£</span>
                </p>
                <p>
                  M.S. student
                </p>
                <p>
                  School of Computer Science and Engineering
                </p>
                <p>
                  Sun Yat-sen University
                </p>
                <p>
                  Email: wuxm65@mail2.sysu.edu.cn
                </p>
                <p style="text-align:left">
                  <a href="https://scholar.google.com/citations?hl=zh-CN&user=Li7oZpsAAAAJ" target="_blank">
                    [<span style="color: #4285F4; margin-right: -2px">G</span>
                    <span style="color: #EA4335; margin-right: -2px">o</span>
                    <span style="color: #FBBC05; margin-right: -2px">o</span>
                    <span style="color: #4285F4; margin-right: -2px">g</span>
                    <span style="color: #34A853; margin-right: -2px">l</span>
                    <span style="color: #EA4335; margin-right: -2px">e</span> &nbsp Scholar]</a> &nbsp;&nbsp;
                  <a href="https://github.com/DravenALG" target="_blank"><strong style="color: black">[GitHub]</strong></a>
                </p>
              </td>

            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 20px;"><tbody>
            <tr>
              <td style="width:100%; vertical-align:middle">
                <h2 id="bio" style="scroll-margin-top: 45px;">
                  Biography
                </h2>
                <p>
                  I'm currently a third-year master student at <a href="https://www.sysu.edu.cn" target="_blank">Sun Yat-sen University</a> (2022.09-now), advised by Prof. <a href="https://www.isee-ai.cn/~zhwshi/" target="_blank">Wei-Shi Zheng</a>, where I develop a good research ability and a nice taste of it.
                  Previously, I obtain my B.E. degree in <a href="https://www.sdu.edu.cn/index.htm" target="_blank">Shandong University</a> (2018.09-2022.06, with GPA ranking 1/354 in grade). At that time, I had my first attempt on scientific research and cultivate the interest in it, advised by Prof. <a href="http://mima.sdu.edu.cn/Members/xinshunxu/index.htm" target="_blank">Xin-Shun Xu</a> and Associate Prof. <a href="https://faculty.sdu.edu.cn/luoxin/zh_CN/index.htm" target="_blank">Xin Luo</a>.
                  I was fortunate to visit <a href="https://www.mq.edu.au" target="_blank">Macquarie university</a> (2024.06-2024.12), completing a fulfilling research journey with Prof. <a href="https://researchers.mq.edu.au/en/persons/longbing-cao" target="_blank">Longbing Cao</a>.
                </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 20px;"><tbody>
            <tr>
              <td style="width:100%; vertical-align:middle">
                <h2 id="bio" style="scroll-margin-top: 45px;">
                  Research Interests
                </h2>

                <p>
                  <em class="ref">
                    Research is for curiosity and fun.
                  </em>
                </p>

                <p>
                  Now I am mainly interested in the areas of <strong>Robotic Manipulation</strong>, <strong>Self-Supervised Learning</strong> and <strong>Generative Modelling</strong>.
                  Previously, I have also participated in various computer vision areas, such as robotic grasping, model compression, hashing retrieval, image restoration, stereo matching, privacy detection, and anomaly detection, which has significantly broadened my horizons.
                </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 20px;"><tbody>
          <tr>
            <td style="width:100%; vertical-align:middle">
              <h2>
                News
              </h2>
              <div class="scrollable" style="max-height:130px; overflow-y:scroll; padding-right:10px; margin-top: 10px; margin-bottom: 10px">
                <p>
                  <span style="font-size: smaller">‚û§</span> [2025-01] One paper accepted in ICRA 2025.
                </p>
                <p>
                  <span style="font-size: smaller">‚û§</span> [2025-01] One paper accepted in IJCV.
                </p>
                <p>
                  <span style="font-size: smaller">‚û§</span> [2024-12] One paper accepted in AAAI 2025.
                </p>
                <p>
                  <span style="font-size: smaller">‚û§</span> [2024-11] One paper accepted in RA-L (My co-first author work MotionGrasp).
                </p>
                <p>
                  <span style="font-size: smaller">‚û§</span> [2024-09] One paper accepted in NeurIPS 2024.
                </p>
                <p>
                  <span style="font-size: smaller">‚û§</span> [2024-09] One paper accepted in CoRL 2024.
                </p>
                <p>
                  <span style="font-size: smaller">‚û§</span> [2024-07] One paper accepted in ACM Multimedia 2024.
                </p>
                <p>
                  <span style="font-size: smaller">‚û§</span> [2024-07] One paper accepted in ECCV 2024 (My first-author work EconomicGrasp).
                </p>
                <p>
                  <span style="font-size: smaller">‚û§</span> [2024-02] Three papers accepted in CVPR 2024.
                </p>
                <p>
                  <span style="font-size: smaller">‚û§</span> [2023-07] One paper accepted in ICCV 2023 (My first-author work ReSTE).
                </p>
                <p>
                  <span style="font-size: smaller">‚û§</span> [2023-02] One paper accepted in CVPR 2023.
                </p>
                <p>
                  <span style="font-size: smaller">‚û§</span> [2022-02] One paper accepted in Pattern Recognition.
                </p>
                <p>
                  <span style="font-size: smaller">‚û§</span> [2021-12] One paper accepted in AAAI 2022 (my first-author work OASIS).
                </p>
              </div>
            </td>
          </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 0px; margin-bottom: -10px;"><tbody>
            <tr>
              <td style="width:80%; vertical-align:middle">
                <h2 id="publication" style="scroll-margin-top: 45px;">Publications</h2>
                <p>
                  Below are my publications.
                  (& means equal contribution, * refers to corresponding author.)
                  <button id="showFullListBtn" class="toggle-button" onclick="showFullList()">[Show Full List]</button>
                  <button id="showSelectedListBtn" class="toggle-button" onclick="showSelectedList()" style="display:none;">[Show Selected List]</button>
                </p>
              </td>
            </tr>
           </tbody></table>

          <table id="selectedPublications" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 20px;"><tbody>
            <tr>
              <td class="paper_image" style="padding: 20px; width:25%;vertical-align:middle">
                <img src="images/DiffuVolume.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td style="width:75%; vertical-align:middle">
                <a href="https://arxiv.org/abs/2308.15989" target="_blank">
                  <span class="papertitle">DiffuVolume: Diffusion Model for Volume based Stereo Matching.</span>
                </a>
                <br>
                Dian Zheng, <strong>Xiao-Ming Wu</strong>, Zuhao Liu, Jingke Meng, Wei-Shi Zheng*.
                <br>
                <em>International Journal of Computer Vision (IJCV)</em>, 2025.
                <br>
                <a href="https://arxiv.org/abs/2308.15989" target="_blank">paper</a>
                /
                <a href="https://github.com/iSEE-Laboratory/DiffuVolume" target="_blank">code</a>
                <p style="margin-bottom: 15px; margin-top: 5px">
                  <strong>(Stereo Matching)</strong> Boost your stereo matching methods with our lightweight, plug-and-play DiffuVolumeüòÄ.
                </p>
              </td>
            </tr>

            <tr>
              <td class="paper_image" style="padding: 20px; width:25%;vertical-align:middle">
                <img src="images/MotionGrasp.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td style="width:75%; vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/document/10764717" target="_blank">
                  <span class="papertitle">MotionGrasp: Long-Term Grasp Motion Tracking for Dynamic Grasping.</span>
                </a>
                <br>
                Nuo Chen&, <strong>Xiao-Ming Wu&</strong>, Guo-Hao Xu, Jian-Jian Jiang, Zibo Chen, Wei-Shi Zheng*.
                <br>
                <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2024.
                <br>
                <a href="https://ieeexplore.ieee.org/document/10764717" target="_blank">paper</a>
                /
                <a href="https://github.com/ChenN-Scott/MotionGrasp" target="_blank">code</a>
                <p style="margin-bottom: 15px; margin-top: 5px">
                  <strong>(Dynamic Grasping)</strong> Track and grasp the moving objects with grasp motionüêá.
                </p>
              </td>
            </tr>

            <tr>
              <td class="paper_image" style="padding: 20px; width:25%;vertical-align:middle">
                <img src="images/DexGYS.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td style="width:75%; vertical-align:middle">
                <a href="https://arxiv.org/abs/2405.19291" target="_blank">
                  <span class="papertitle">Grasp as You Say: Language-guided Dexterous Grasp Generation.</span>
                </a>
                <br>
                Yi-Lin Wei, Jian-Jian Jiang, Chengyi Xing, Xiantuo Tan, <strong>Xiao-Ming Wu</strong>, Hao Li, Mark Cutkosky, Wei-Shi Zheng*.
                <br>
                <em>Neural Information Processing Systems (NeurIPS)</em>, 2024.
                <br>
                <a href="https://isee-laboratory.github.io/DexGYS/" target="_blank">page</a>
                /
                <a href="https://arxiv.org/abs/2405.19291" target="_blank">paper</a>
                /
                <a href="https://github.com/iSEE-Laboratory/Grasp-as-You-Say" target="_blank">code</a>
                <p style="margin-bottom: 15px; margin-top: 5px">
                  <strong>(Dexterous Grasping)</strong> Guide dexterous grasping with what you sayüéôÔ∏è.
                </p>
              </td>
            </tr>

            <tr>
              <td class="paper_image" style="padding: 20px; width:25%;vertical-align:middle">
                <img src="images/EconomicGrasp.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td style="width:75%; vertical-align:middle">
                <a href="https://link.springer.com/chapter/10.1007/978-3-031-73383-3_21" target="_blank">
                  <span class="papertitle">An Economic Framework for 6-DoF Grasp Detection.</span>
                </a>
                <br>
                <strong>Xiao-Ming Wu&</strong>, Jia-Feng Cai&, Jian-Jian Jiang, Dian Zheng, Yi-Lin Wei, Wei-Shi Zheng*.
                <br>
                <em>European Conference on Computer Vision (ECCV)</em>, 2024.
                <br>
                <a href="https://link.springer.com/chapter/10.1007/978-3-031-73383-3_21" target="_blank">paper</a>
                /
                <a href="https://github.com/iSEE-Laboratory/EconomicGrasp" target="_blank">code</a>
                <p style="margin-bottom: 15px; margin-top: 5px">
                  <strong>(6-DoF Grasping)</strong> Speed up your 6-DoF grasping training 10x without performance dropüöÑ.
                </p>
              </td>
            </tr>

            <tr>
              <td class="paper_image" style="padding: 20px; width:25%;vertical-align:middle">
                <img src="images/DiffUIR.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td style="width:75%; vertical-align:middle">
                <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Selective_Hourglass_Mapping_for_Universal_Image_Restoration_Based_on_Diffusion_CVPR_2024_paper.html" target="_blank">
                  <span class="papertitle">Selective Hourglass Mapping for Universal Image Restoration Based on Diffusion Model.</span>
                </a>
                <br>
                Dian Zheng, <strong>Xiao-Ming Wu</strong>, Shuzhou Yang, Jian Zhang, Jian-Fang Hu, Wei-Shi Zheng*.
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2024.
                <br>
                <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Zheng_Selective_Hourglass_Mapping_for_Universal_Image_Restoration_Based_on_Diffusion_CVPR_2024_paper.html" target="_blank">paper</a>
                /
                <a href="https://github.com/iSEE-Laboratory/DiffUIR" target="_blank">code</a>
                <p style="margin-bottom: 15px; margin-top: 5px">
                  <strong>(Image Restoration)</strong> Hourglass diffusion is a good way for universal image restorationüåÜ.
                </p>
              </td>
            </tr>

            <tr>
              <td class="paper_image" style="padding: 20px; width:25%;vertical-align:middle">
                <img src="images/DGTR.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td style="width:75%; vertical-align:middle">
                <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Dexterous_Grasp_Transformer_CVPR_2024_paper.html" target="_blank">
                  <span class="papertitle">Dexterous Grasp Transformer.</span>
                </a>
                <br>
                Guo-Hao Xu&, Yi-Lin Wei&, Dian Zheng, <strong>Xiao-Ming Wu</strong>, Wei-Shi Zheng*.
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2024.
                <br>
                <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Xu_Dexterous_Grasp_Transformer_CVPR_2024_paper.html" target="_blank">paper</a>
                /
                <a href="https://github.com/iSEE-Laboratory/DGTR" target="_blank">code</a>
                <p style="margin-bottom: 15px; margin-top: 5px">
                  <strong>(Dexterous Grasping)</strong> Generate a diverse set of feasible dexterous grasp only in one passü¶æ!
                </p>
              </td>
            </tr>

            <tr>
              <td class="paper_image" style="padding: 20px; width:25%;vertical-align:middle">
                <img src="images/ReSTE.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td style="width:75%; vertical-align:middle">
                <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Estimator_Meets_Equilibrium_Perspective_A_Rectified_Straight_Through_Estimator_for_ICCV_2023_paper.html" target="_blank">
                  <span class="papertitle">Estimator Meets Equilibrium Perspective: A Rectified Straight Through Estimator for Binary Neural Networks Training.</span>
                </a>
                <br>
                <strong>Xiao-Ming Wu</strong>, Dian Zheng, Zuhao Liu, Wei-Shi Zheng*.
                <br>
                <em>IEEE International Conference on Computer Vision (ICCV)</em>, 2023.
                <br>
                <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Estimator_Meets_Equilibrium_Perspective_A_Rectified_Straight_Through_Estimator_for_ICCV_2023_paper.html" target="_blank">paper</a>
                /
                <a href="https://github.com/DravenALG/ReSTE" target="_blank">code</a>
                <p style="margin-bottom: 15px; margin-top: 5px">
                  <strong>(Binary Neural Networks)</strong> Simple and effective gradient estimator for binary neural network trainingü§©!
                </p>
              </td>
            </tr>

            <tr>
              <td class="paper_image" style="padding: 20px; width:25%;vertical-align:middle">
                <img src="images/OASIS.png" alt="PontTuset" width="200" style="border-style: none">
              </td>
              <td style="width:75%; vertical-align:middle">
                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20346" target="_blank">
                  <span class="papertitle">Online Enhanced Semantic Hashing Towards Effective and Efficient Retrieval for Streaming Multi-Modal Data.</span>
                </a>
                <br>
                <strong>Xiao-Ming Wu</strong>, Xin Luo*, Yu-Wei Zhan, Chen-Lu Ding, Zhen-Duo Chen, Xin-Shun Xu.
                <br>
                <em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2022.
                <br>
                <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20346" target="_blank">paper</a>
                /
                <a href="https://github.com/DravenALG/OASIS" target="_blank">code</a>
                <p style="margin-bottom: 15px; margin-top: 5px">
                  <strong>(Hashing Retrieval)</strong> New benchmark and baseline for online multi-modal hashingüôå.
                </p>
              </td>
            </tr>


          </tbody></table>

          <table id="fullPublications" style="display:none; width:100%;border:0px;border-spacing:0px; border-collapse:separate; margin-right:auto; margin-left:auto; padding-left:20px;"><tbody">
            <tr>
              <td style="padding-left: 20px; padding-bottom: 25px ; width:100%; vertical-align:middle">
                <span class="papertitle">UGotMe: An Embodied System for Affective Human-Robot Interaction.</span>
                <br>
                Peizhen Li, Longbing Cao*, <strong>Xiao-Ming Wu</strong>, Xiaohan Yu, Runze Yang.
                <br>
                <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2025.
                <br>
              </td>
            </tr>
            
            <tr>
              <td style="padding-left: 20px; padding-bottom: 25px ; width:100%; vertical-align:middle">
                <span class="papertitle">DiffuVolume: Diffusion Model for Volume based Stereo Matching.</span>
                <br>
                Dian Zheng, <strong>Xiao-Ming Wu</strong>, Zuhao Liu, Jingke Meng, Wei-Shi Zheng*.
                <br>
                <em>International Journal of Computer Vision (IJCV)</em>, 2025.
                <br>
              </td>
            </tr>

            <tr>
              <td style="padding-left: 20px; padding-bottom: 25px ; width:100%; vertical-align:middle">
                <span class="papertitle">PeriodicMFD: A Periodic-based Framework for Multi-source Fault Diagnosis.</span>
                <br>
                Jianbo Zheng , Chao Yang*, Tairui Zhang, Bin Jiang, Xuhui Fan, <strong>Xiao-Ming Wu</strong>, Haidong Shao*.
                <br>
                <em>IEEE Transactions on Transportation Electrification (TTE)</em>, 2025.
                <br>
              </td>
            </tr>

            <tr>
              <td style="padding-left: 20px; padding-bottom: 25px ; width:100%; vertical-align:middle">
                <span class="papertitle">Dynamic Spectral Graph Anomaly Detection.</span>
                <br>
                Jianbo Zheng, Chao Yang*, Tairui Zhang, Longbing Cao*, Bin Jiang, Xuhui Fan, <strong>Xiao-Ming Wu</strong>, Xianxun Zhu.
                <br>
                <em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2025.
                <br>
              </td>
            </tr>

            <tr>
              <td style="padding-left: 20px; padding-bottom: 25px ; width:100%; vertical-align:middle">
                <span class="papertitle">MotionGrasp: Long-Term Grasp Motion Tracking for Dynamic Grasping.</span>
                <br>
                Nuo Chen&, <strong>Xiao-Ming Wu&</strong>, Guo-Hao Xu, Jian-Jian Jiang, Zibo Chen, Wei-Shi Zheng*.
                <br>
                <em>IEEE Robotics and Automation Letters (RA-L)</em>, 2024.
                <br>
              </td>
            </tr>

            <tr>
              <td style="padding-left: 20px; padding-bottom: 25px ; width:100%; vertical-align:middle">
                <span class="papertitle">Grasp as You Say: Language-guided Dexterous Grasp Generation.</span>
                <br>
                Yi-Lin Wei, Jian-Jian Jiang, Chengyi Xing, Xiantuo Tan, <strong>Xiao-Ming Wu</strong>, Hao Li, Mark Cutkosky, Wei-Shi Zheng*.
                <br>
                <em>Neural Information Processing Systems (NeurIPS) </em>, 2024.
                <br>
              </td>
            </tr>

            <tr>
              <td style="padding-left: 20px; padding-bottom: 25px ; width:100%; vertical-align:middle">
                <span class="papertitle">Real-to-Sim Grasp: Rethinking the Gap between Simulation and Real World in Grasp Detection.</span>
                <br>
                Jia-Feng Cai, Zibo Chen, <strong>Xiao-Ming Wu</strong>, Jian-Jian Jiang, Yi-Lin Wei, Wei-Shi Zheng*.
                <br>
                <em>Conference on Robot Learning (CoRL)</em>, 2024.
                <br>
              </td>
            </tr>

            <tr>
              <td style="padding-left: 20px; padding-bottom: 25px ; width:100%; vertical-align:middle">
                <span class="papertitle">iGrasp: An Interactive 2D-3D Framework for 6-DoF Grasp Detection.</span>
                <br>
                Jian-Jian Jiang, <strong>Xiao-Ming Wu</strong>, Chen Zibo, Yi-Lin Wei, Wei-Shi Zheng*.
                <br>
                <em>International Conference on Pattern Recognition (ICPR)</em>, 2024.
                <br>
              </td>
            </tr>

            <tr>
              <td style="padding-left: 20px; padding-bottom: 25px ; width:100%; vertical-align:middle">
                <span class="papertitle">PixelFade: Privacy-preserving Person Re-identification with Noise-guided Progressive Replacement.</span>
                <br>
                Delong Zhang, Yi-Xing Peng, <strong>Xiao-Ming Wu</strong>, Ancong Wu*, Wei-Shi Zheng.
                <br>
                <em>ACM Multimedia (MM)</em>, 2024.
                <br>
              </td>
            </tr>

            <tr>
              <td style="padding-left: 20px; padding-bottom: 25px ; width:100%; vertical-align:middle">
                <span class="papertitle">An Economic Framework for 6-DoF Grasp Detection.</span>
                <br>
                <strong>Xiao-Ming Wu&</strong>, Jia-Feng Cai&, Jian-Jian Jiang, Dian Zheng, Yi-Lin Wei, Wei-Shi Zheng*.
                <br>
                <em>European Conference on Computer Vision (ECCV)</em>, 2024.
                <br>
              </td>
            </tr>

            <tr>
              <td style="padding-left: 20px;padding-bottom: 25px ;  width:100%; vertical-align:middle">
                <span class="papertitle">Selective Hourglass Mapping for Universal Image Restoration Based on Diffusion Model.</span>
                <br>
                Dian Zheng, <strong>Xiao-Ming Wu</strong>, Shuzhou Yang, Jian Zhang, Jian-Fang Hu, Wei-Shi Zheng*.
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2024.
                <br>
              </td>
            </tr>

            <tr>
              <td style="padding-left: 20px;padding-bottom: 25px ;  width:100%; vertical-align:middle">
                <span class="papertitle">Single-View Scene Point Cloud Human Grasp Generation.</span>
                <br>
                Yan-Kang Wang, Chengyi Xing, Yi-Lin Wei, <strong>Xiao-Ming Wu</strong>, Wei-Shi Zheng*.
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2024.
                <br>
              </td>
            </tr>

            <tr>
              <td style="padding-left: 20px;padding-bottom: 25px ;  width:100%; vertical-align:middle">
                <span class="papertitle">Dexterous Grasp Transformer.</span>
                <br>
                Guo-Hao Xu&, Yi-Lin Wei&, Dian Zheng, <strong>Xiao-Ming Wu</strong>, Wei-Shi Zheng*.
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2024.
                <br>
              </td>
            </tr>

            <tr>
              <td style="padding-left: 20px;padding-bottom: 25px ;  width:100%; vertical-align:middle">
                <span class="papertitle">Estimator Meets Equilibrium Perspective: A Rectified Straight Through Estimator for Binary Neural Networks Training.</span>
                <br>
                <strong>Xiao-Ming Wu</strong>, Dian Zheng, Zuhao Liu, Wei-Shi Zheng*.
                <br>
                <em>IEEE International Conference on Computer Vision (ICCV)</em>, 2023.
                <br>
              </td>
            </tr>

            <tr>
              <td style="padding-left: 20px;padding-bottom: 25px ;  width:100%; vertical-align:middle">
                <span class="papertitle">Generating Anomalies for Video Anomaly Detection with Prompt-based Feature Mapping.</span>
                <br>
                Zuhao Liu, <strong>Xiao-Ming Wu</strong>, Dian Zheng, Kun-Yu Lin, Wei-Shi Zheng*.
                <br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023.
                <br>
              </td>
            </tr>

            <tr>
              <td style="padding-left: 20px;padding-bottom: 25px ;  width:100%; vertical-align:middle">
                <span class="papertitle">Weakly-Supervised Online Hashing with Refined Pseudo Tags.</span>
                <br>
                Chen-Lu Ding, Xin Luo*, <strong>Xiao-Ming Wu</strong>, Yu-Wei Zhan, Rui Li, Hui Zhang, and Xin-Shun Xu.
                <br>
                <em>Conference on Information and Knowledge Management (CIKM)</em>, 2022
                <br>
              </td>
            </tr>

            <tr>
              <td style="padding-left: 20px;padding-bottom: 25px ;  width:100%; vertical-align:middle">
                <span class="papertitle">Discrete Online Cross-Modal Hashing.</span>
                <br>
                Yu-Wei Zhan, Yong-Xin Wang, Yu Sun, <strong>Xiao-Ming Wu</strong>, Xin Luo*, and Xin-Shun Xu.
                <br>
                <em>Pattern Recognition (PR)</em>, 2022.
                <br>
              </td>
            </tr>

            <tr>
              <td style="padding-left: 20px;padding-bottom: 25px ;  width:100%; vertical-align:middle">
                <span class="papertitle">Online Enhanced Semantic Hashing Towards Effective and Efficient Retrieval for Streaming Multi-Modal Data.</span>
                <br>
                <strong>Xiao-Ming Wu</strong>, Xin Luo*, Yu-Wei Zhan, Chen-Lu Ding, Zhen-Duo Chen, Xin-Shun Xu.
                <br>
                <em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2022.
                <br>
              </td>
            </tr>
          </tbody></table>




          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 20px;"><tbody>
          <tr>
            <td style="width:100%; vertical-align:middle">
              <h2 id="service" style="scroll-margin-top: 45px;">
                Services and Activities
              </h2>
              <p>
                <div style="padding-bottom: 5px"><strong>Journal Reviewer:</strong></div>
                <div style="padding-bottom: 5px">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</div>
                <div style="padding-bottom: 5px">Pattern Recognition (PR)</div>
              </p>
              <p>
                <div style="padding-bottom: 5px"><strong>Conference Reviewer:</strong></div>
                <div style="padding-bottom: 5px">IEEE International Conference on Computer Vision (ICCV) 2025</div>
                <div style="padding-bottom: 5px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2024, 2025</div>
                <div style="padding-bottom: 5px">ACM Multimedia (MM) 2024, 2025</div>
                <div style="padding-bottom: 5px">IEEE International Conference on Multimedia&Expo (ICME) 2025</div>
              </p>
            </td>
          </tr>

          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto; padding-left:20px; padding-bottom: 20px;"><tbody>
          <tr>
            <td style="width:100%; vertical-align:middle">
              <h2 id="award" style="scroll-margin-top: 45px;">
                Honours and Awards
              </h2>
              <p>

              <div style="padding-bottom: 5px"> First Prize Scholarship of Sun Yat-Sen University for Graduate Student (‰∏≠Â±±Â§ßÂ≠¶Á°ïÂ£´Á†îÁ©∂Áîü‰∏ÄÁ≠âÂ•ñÂä©Èáë), 2022, 2023, 2024. </div>
              <div style="padding-bottom: 5px"> National Scholarship of China for Graduate Student (Á†îÁ©∂ÁîüÂõΩÂÆ∂Â•ñÂ≠¶Èáë), 2023. </div>
                <div style="padding-bottom: 5px"> Honorable Bachelor Degree of Shandong University (Â±±‰∏úÂ§ßÂ≠¶Ëç£Ë™âÂ≠¶Â£´Â≠¶‰Ωç), 2022. </div>
                <div style="padding-bottom: 5px"> Excellent Graduate in Shandong University (Â±±‰∏úÂ§ßÂ≠¶‰ºòÁßÄÊØï‰∏öÁîü), 2022. </div>
                <div style="padding-bottom: 5px"> Excellent Graduation Thesis of Shandong University (Â±±‰∏úÂ§ßÂ≠¶‰ºòÁßÄÊØï‰∏öËÆ∫Êñá), 2022. </div>
                <div style="padding-bottom: 5px"> National Scholarship of China for Undergraduate Student  (Êú¨ÁßëÁîüÂõΩÂÆ∂Â•ñÂ≠¶Èáë), 2019, 2021. </div>
                <div style="padding-bottom: 5px"> First Prize Scholarship of Shandong University for Undergraduate Student (Â±±‰∏úÂ§ßÂ≠¶Êú¨ÁßëÁîü‰∏ÄÁ≠âÂ•ñÂ≠¶Èáë), 2019, 2020, 2021. </div>
                <div style="padding-bottom: 5px"> Three Good Student of Shandong University (Â±±‰∏úÂ§ßÂ≠¶‰∏âÂ•ΩÂ≠¶Áîü), 2021 </div>
              </p>
            </td>
          </tr>
          </tbody></table>

        </td>
      </tr>
    </table>

    <script src="script.js"></script>

  </body>
</html>
